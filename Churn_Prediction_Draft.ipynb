{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, KFold\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    make_scorer\n",
        ")\n",
        "\n",
        "# Base classifiers\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Ensemble methods\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    ExtraTreesClassifier,\n",
        "    StackingClassifier\n",
        ")\n"
      ],
      "metadata": {
        "id": "-q5MZl283K8f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"churn.csv\")\n"
      ],
      "metadata": {
        "id": "prwgtISP4cZZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwdH2TlVMp_i",
        "outputId": "43b9c92c-cc8c-4fb1-f9d0-453e59690022"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3333 entries, 0 to 3332\n",
            "Data columns (total 21 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   State           3333 non-null   object \n",
            " 1   Account Length  3333 non-null   int64  \n",
            " 2   Area Code       3333 non-null   int64  \n",
            " 3   Phone           3333 non-null   object \n",
            " 4   Int'l Plan      3333 non-null   object \n",
            " 5   VMail Plan      3333 non-null   object \n",
            " 6   VMail Message   3333 non-null   int64  \n",
            " 7   Day Mins        3333 non-null   float64\n",
            " 8   Day Calls       3333 non-null   int64  \n",
            " 9   Day Charge      3333 non-null   float64\n",
            " 10  Eve Mins        3333 non-null   float64\n",
            " 11  Eve Calls       3333 non-null   int64  \n",
            " 12  Eve Charge      3333 non-null   float64\n",
            " 13  Night Mins      3333 non-null   float64\n",
            " 14  Night Calls     3333 non-null   int64  \n",
            " 15  Night Charge    3333 non-null   float64\n",
            " 16  Intl Mins       3333 non-null   float64\n",
            " 17  Intl Calls      3333 non-null   int64  \n",
            " 18  Intl Charge     3333 non-null   float64\n",
            " 19  CustServ Calls  3333 non-null   int64  \n",
            " 20  Churn?          3333 non-null   object \n",
            "dtypes: float64(8), int64(8), object(5)\n",
            "memory usage: 546.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "3liyl6j4Ms3e",
        "outputId": "82abafc5-ccfc-4dd0-fd6b-a0d2db1cf0f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  State  Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
              "0    KS             128        415  382-4657         no        yes   \n",
              "1    OH             107        415  371-7191         no        yes   \n",
              "2    NJ             137        415  358-1921         no         no   \n",
              "3    OH              84        408  375-9999        yes         no   \n",
              "4    OK              75        415  330-6626        yes         no   \n",
              "\n",
              "   VMail Message  Day Mins  Day Calls  Day Charge  ...  Eve Calls  Eve Charge  \\\n",
              "0             25     265.1        110       45.07  ...         99       16.78   \n",
              "1             26     161.6        123       27.47  ...        103       16.62   \n",
              "2              0     243.4        114       41.38  ...        110       10.30   \n",
              "3              0     299.4         71       50.90  ...         88        5.26   \n",
              "4              0     166.7        113       28.34  ...        122       12.61   \n",
              "\n",
              "   Night Mins  Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
              "0       244.7           91         11.01       10.0           3         2.70   \n",
              "1       254.4          103         11.45       13.7           3         3.70   \n",
              "2       162.6          104          7.32       12.2           5         3.29   \n",
              "3       196.9           89          8.86        6.6           7         1.78   \n",
              "4       186.9          121          8.41       10.1           3         2.73   \n",
              "\n",
              "   CustServ Calls  Churn?  \n",
              "0               1  False.  \n",
              "1               1  False.  \n",
              "2               0  False.  \n",
              "3               2  False.  \n",
              "4               3  False.  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a292fc41-dc8d-4e45-9409-f36c15cafb99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Account Length</th>\n",
              "      <th>Area Code</th>\n",
              "      <th>Phone</th>\n",
              "      <th>Int'l Plan</th>\n",
              "      <th>VMail Plan</th>\n",
              "      <th>VMail Message</th>\n",
              "      <th>Day Mins</th>\n",
              "      <th>Day Calls</th>\n",
              "      <th>Day Charge</th>\n",
              "      <th>...</th>\n",
              "      <th>Eve Calls</th>\n",
              "      <th>Eve Charge</th>\n",
              "      <th>Night Mins</th>\n",
              "      <th>Night Calls</th>\n",
              "      <th>Night Charge</th>\n",
              "      <th>Intl Mins</th>\n",
              "      <th>Intl Calls</th>\n",
              "      <th>Intl Charge</th>\n",
              "      <th>CustServ Calls</th>\n",
              "      <th>Churn?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KS</td>\n",
              "      <td>128</td>\n",
              "      <td>415</td>\n",
              "      <td>382-4657</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>25</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>45.07</td>\n",
              "      <td>...</td>\n",
              "      <td>99</td>\n",
              "      <td>16.78</td>\n",
              "      <td>244.7</td>\n",
              "      <td>91</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1</td>\n",
              "      <td>False.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OH</td>\n",
              "      <td>107</td>\n",
              "      <td>415</td>\n",
              "      <td>371-7191</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>26</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>27.47</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>16.62</td>\n",
              "      <td>254.4</td>\n",
              "      <td>103</td>\n",
              "      <td>11.45</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "      <td>False.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NJ</td>\n",
              "      <td>137</td>\n",
              "      <td>415</td>\n",
              "      <td>358-1921</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>41.38</td>\n",
              "      <td>...</td>\n",
              "      <td>110</td>\n",
              "      <td>10.30</td>\n",
              "      <td>162.6</td>\n",
              "      <td>104</td>\n",
              "      <td>7.32</td>\n",
              "      <td>12.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0</td>\n",
              "      <td>False.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OH</td>\n",
              "      <td>84</td>\n",
              "      <td>408</td>\n",
              "      <td>375-9999</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>50.90</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>5.26</td>\n",
              "      <td>196.9</td>\n",
              "      <td>89</td>\n",
              "      <td>8.86</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2</td>\n",
              "      <td>False.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OK</td>\n",
              "      <td>75</td>\n",
              "      <td>415</td>\n",
              "      <td>330-6626</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>28.34</td>\n",
              "      <td>...</td>\n",
              "      <td>122</td>\n",
              "      <td>12.61</td>\n",
              "      <td>186.9</td>\n",
              "      <td>121</td>\n",
              "      <td>8.41</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.73</td>\n",
              "      <td>3</td>\n",
              "      <td>False.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a292fc41-dc8d-4e45-9409-f36c15cafb99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a292fc41-dc8d-4e45-9409-f36c15cafb99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a292fc41-dc8d-4e45-9409-f36c15cafb99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-caf29082-3909-468f-b9fd-2c081aea8706\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-caf29082-3909-468f-b9fd-2c081aea8706')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-caf29082-3909-468f-b9fd-2c081aea8706 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert target variable to binary\n",
        "df['Churn?'] = df['Churn?'].str.strip().map({'False.': 0, 'True.': 1})\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df.drop(['Phone'], axis=1, inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "cat_cols = ['State', \"Int'l Plan\", 'VMail Plan']\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n"
      ],
      "metadata": {
        "id": "bd3VJJPd4iKf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "RtO75x455aqC",
        "outputId": "df6edae0-7511-41f3-adc5-38eba9c7436a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   State  Account Length  Area Code  Int'l Plan  VMail Plan  VMail Message  \\\n",
              "0     16             128        415           0           1             25   \n",
              "1     35             107        415           0           1             26   \n",
              "2     31             137        415           0           0              0   \n",
              "3     35              84        408           1           0              0   \n",
              "4     36              75        415           1           0              0   \n",
              "\n",
              "   Day Mins  Day Calls  Day Charge  Eve Mins  Eve Calls  Eve Charge  \\\n",
              "0     265.1        110       45.07     197.4         99       16.78   \n",
              "1     161.6        123       27.47     195.5        103       16.62   \n",
              "2     243.4        114       41.38     121.2        110       10.30   \n",
              "3     299.4         71       50.90      61.9         88        5.26   \n",
              "4     166.7        113       28.34     148.3        122       12.61   \n",
              "\n",
              "   Night Mins  Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
              "0       244.7           91         11.01       10.0           3         2.70   \n",
              "1       254.4          103         11.45       13.7           3         3.70   \n",
              "2       162.6          104          7.32       12.2           5         3.29   \n",
              "3       196.9           89          8.86        6.6           7         1.78   \n",
              "4       186.9          121          8.41       10.1           3         2.73   \n",
              "\n",
              "   CustServ Calls  Churn?  \n",
              "0               1       0  \n",
              "1               1       0  \n",
              "2               0       0  \n",
              "3               2       0  \n",
              "4               3       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f23b9cb-a42a-465d-a12d-21fca5402dd8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Account Length</th>\n",
              "      <th>Area Code</th>\n",
              "      <th>Int'l Plan</th>\n",
              "      <th>VMail Plan</th>\n",
              "      <th>VMail Message</th>\n",
              "      <th>Day Mins</th>\n",
              "      <th>Day Calls</th>\n",
              "      <th>Day Charge</th>\n",
              "      <th>Eve Mins</th>\n",
              "      <th>Eve Calls</th>\n",
              "      <th>Eve Charge</th>\n",
              "      <th>Night Mins</th>\n",
              "      <th>Night Calls</th>\n",
              "      <th>Night Charge</th>\n",
              "      <th>Intl Mins</th>\n",
              "      <th>Intl Calls</th>\n",
              "      <th>Intl Charge</th>\n",
              "      <th>CustServ Calls</th>\n",
              "      <th>Churn?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>45.07</td>\n",
              "      <td>197.4</td>\n",
              "      <td>99</td>\n",
              "      <td>16.78</td>\n",
              "      <td>244.7</td>\n",
              "      <td>91</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>107</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>27.47</td>\n",
              "      <td>195.5</td>\n",
              "      <td>103</td>\n",
              "      <td>16.62</td>\n",
              "      <td>254.4</td>\n",
              "      <td>103</td>\n",
              "      <td>11.45</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31</td>\n",
              "      <td>137</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>41.38</td>\n",
              "      <td>121.2</td>\n",
              "      <td>110</td>\n",
              "      <td>10.30</td>\n",
              "      <td>162.6</td>\n",
              "      <td>104</td>\n",
              "      <td>7.32</td>\n",
              "      <td>12.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "      <td>84</td>\n",
              "      <td>408</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>50.90</td>\n",
              "      <td>61.9</td>\n",
              "      <td>88</td>\n",
              "      <td>5.26</td>\n",
              "      <td>196.9</td>\n",
              "      <td>89</td>\n",
              "      <td>8.86</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>75</td>\n",
              "      <td>415</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>28.34</td>\n",
              "      <td>148.3</td>\n",
              "      <td>122</td>\n",
              "      <td>12.61</td>\n",
              "      <td>186.9</td>\n",
              "      <td>121</td>\n",
              "      <td>8.41</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.73</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f23b9cb-a42a-465d-a12d-21fca5402dd8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f23b9cb-a42a-465d-a12d-21fca5402dd8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f23b9cb-a42a-465d-a12d-21fca5402dd8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f93c52b8-909c-4be6-b1d0-6c29dabd7fe0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f93c52b8-909c-4be6-b1d0-6c29dabd7fe0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f93c52b8-909c-4be6-b1d0-6c29dabd7fe0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3333,\n  \"fields\": [\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 0,\n        \"max\": 50,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          47,\n          25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Account Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 1,\n        \"max\": 243,\n        \"num_unique_values\": 212,\n        \"samples\": [\n          172,\n          189,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Area Code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42,\n        \"min\": 408,\n        \"max\": 510,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          415,\n          408,\n          510\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Int'l Plan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VMail Plan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VMail Message\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 0,\n        \"max\": 51,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          44,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day Mins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54.46738920237142,\n        \"min\": 0.0,\n        \"max\": 350.8,\n        \"num_unique_values\": 1667,\n        \"samples\": [\n          87.6,\n          115.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day Calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 165,\n        \"num_unique_values\": 119,\n        \"samples\": [\n          125,\n          59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day Charge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.259434553930507,\n        \"min\": 0.0,\n        \"max\": 59.64,\n        \"num_unique_values\": 1667,\n        \"samples\": [\n          14.89,\n          19.67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Eve Mins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.71384442581193,\n        \"min\": 0.0,\n        \"max\": 363.7,\n        \"num_unique_values\": 1611,\n        \"samples\": [\n          215.1,\n          219.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Eve Calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 170,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          93,\n          142\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Eve Charge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.310667643110339,\n        \"min\": 0.0,\n        \"max\": 30.91,\n        \"num_unique_values\": 1440,\n        \"samples\": [\n          24.85,\n          14.19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Night Mins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.5738470136583,\n        \"min\": 23.2,\n        \"max\": 395.0,\n        \"num_unique_values\": 1591,\n        \"samples\": [\n          311.1,\n          179.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Night Calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 33,\n        \"max\": 175,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          60,\n          73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Night Charge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2758728376600317,\n        \"min\": 1.04,\n        \"max\": 17.77,\n        \"num_unique_values\": 933,\n        \"samples\": [\n          6.2,\n          6.86\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Intl Mins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7918395484084204,\n        \"min\": 0.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 162,\n        \"samples\": [\n          16.6,\n          14.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Intl Calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          3,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Intl Charge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7537726126630453,\n        \"min\": 0.0,\n        \"max\": 5.4,\n        \"num_unique_values\": 162,\n        \"samples\": [\n          4.48,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CustServ Calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Churn?\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Churn?', axis=1)  # Features\n",
        "y = df['Churn?']               # Target\n"
      ],
      "metadata": {
        "id": "PpnKp9gc5f0T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "dRulH4Ig6ave"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Decision Tree\n",
        "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = dt.predict(X_test)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UAEjuTI6EW5",
        "outputId": "a94189fd-0884-4104-d20a-8ea1748d4f79"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[846   9]\n",
            " [ 53  92]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       855\n",
            "           1       0.91      0.63      0.75       145\n",
            "\n",
            "    accuracy                           0.94      1000\n",
            "   macro avg       0.93      0.81      0.86      1000\n",
            "weighted avg       0.94      0.94      0.93      1000\n",
            "\n",
            "Accuracy: 0.938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "recall for 1 is very low"
      ],
      "metadata": {
        "id": "tNO3eHyBe8hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_all, X_test, y_train_all, y_test = train_test_split(X, y, test_size=.3, random_state=42, stratify=y)\n",
        "\n"
      ],
      "metadata": {
        "id": "1E19sZlfbt0g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_all = scaler.fit_transform(X_train_all)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "NAJMpKf16tq9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zig8PFE47BZw",
        "outputId": "4fb436fd-3a52-4a13-9d06-025a9fba2f1d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.90235656,  0.71072961, -0.5107321 , ...,  1.44537268,\n",
              "         1.01225356, -1.20282632],\n",
              "       [ 1.57813912,  1.28536821,  1.75659106, ..., -1.03104431,\n",
              "        -2.08997043, -0.43295148],\n",
              "       [ 0.96993481, -0.58845332,  1.75659106, ..., -0.61830814,\n",
              "         0.45176772,  1.87667306],\n",
              "       ...,\n",
              "       [ 1.3078261 ,  0.11110672, -0.5107321 , ...,  0.20716419,\n",
              "         0.62121693,  1.10679821],\n",
              "       [-0.65194334, -0.76334332, -0.67779801, ..., -1.85651664,\n",
              "        -3.60197876,  1.10679821],\n",
              "       [-1.26014765, -0.51350045, -0.67779801, ..., -0.20557198,\n",
              "        -0.25209823,  1.10679821]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "num_splits = 7\n",
        "kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "models = []\n",
        "\n",
        "for train_idx, val_idx in kf.split(X_train_all_scaled, y_train_all):\n",
        "    # Use numpy indexing since X_train_all_scaled is np.ndarray\n",
        "    X_train_fold = X_train_all_scaled[train_idx]\n",
        "    y_train_fold = y_train_all.iloc[train_idx]  # y_train_all can stay pandas Series\n",
        "\n",
        "    model = DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=42)\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "    models.append(model)\n"
      ],
      "metadata": {
        "id": "P5X5z4vkuHeI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect predicted class labels (0 or 1) from each model for X_test\n",
        "test_preds_class = []\n",
        "\n",
        "for model in models:\n",
        "    preds = model.predict(X_test)  # predicted classes (0 or 1)\n",
        "    test_preds_class.append(preds)\n",
        "\n",
        "# Convert to numpy array: shape (5, number_of_test_samples)\n",
        "test_preds_class = np.array(test_preds_class)\n",
        "\n",
        "# For each test sample, count how many models predicted class 1\n",
        "votes_for_class_1 = np.sum(test_preds_class == 1, axis=0)\n",
        "\n",
        "# Majority vote: if >=3 models predict class 1, final prediction = 1; else 0\n",
        "y_pred= (votes_for_class_1 >= num_splits//2+1).astype(int)\n"
      ],
      "metadata": {
        "id": "bKC8urkxc-VS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0cr3ZkNbPpI",
        "outputId": "d20f69a9-6d88-4998-b8e3-98b7fc1c2c22"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.915\n",
            "Confusion Matrix:\n",
            " [[804  51]\n",
            " [ 34 111]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95       855\n",
            "           1       0.69      0.77      0.72       145\n",
            "\n",
            "    accuracy                           0.92      1000\n",
            "   macro avg       0.82      0.85      0.84      1000\n",
            "weighted avg       0.92      0.92      0.92      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "precision and recall for 1 is very low"
      ],
      "metadata": {
        "id": "oqflOl9XfZuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "feat_importance = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importance.nlargest(10).plot(kind='barh')\n",
        "plt.title(\"Top 10 Important Features\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "FWp8SUpK55f9",
        "outputId": "56697833-f6e5-4877-deee-1de0c3968213"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#1, Make sure these are pandas objects\n",
        "X_train_all = pd.DataFrame(X_train_all)\n",
        "y_train_all = pd.Series(y_train_all)\n",
        "\n",
        "\n",
        "\n",
        "# 2. Create 5 Random Forest models using Stratified K-Fold\n",
        "num_splits = 7\n",
        "kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "models = []\n",
        "\n",
        "for train_idx, val_idx in kf.split(X_train_all, y_train_all):\n",
        "    X_train, y_train = X_train_all.iloc[train_idx], y_train_all.iloc[train_idx]\n",
        "\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        max_depth=5\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "    models.append(rf)\n",
        "\n",
        "# 3. Collect predictions from each model for the same test set\n",
        "test_preds_class = []\n",
        "\n",
        "for model in models:\n",
        "    preds = model.predict(X_test)  # class labels (0 or 1)\n",
        "    test_preds_class.append(preds)\n",
        "\n",
        "# 4. Stack and apply majority voting\n",
        "test_preds_class = np.array(test_preds_class)  # shape: (5, num_samples)\n",
        "votes_for_class_1 = np.sum(test_preds_class == 1, axis=0)\n",
        "\n",
        "# Majority voting: at least 3 out of 5 models vote for class 1\n",
        "y_pred = (votes_for_class_1 >= (num_splits // 2 + 1)).astype(int)\n",
        "\n",
        "# 5. Evaluate\n",
        "print(classification_report(y_test, y_pred, digits=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coVWkmHSusnK",
        "outputId": "360b06f3-e2fb-446c-e235-32eff534a94a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.960     0.936     0.948       855\n",
            "           1      0.671     0.772     0.718       145\n",
            "\n",
            "    accuracy                          0.912      1000\n",
            "   macro avg      0.816     0.854     0.833      1000\n",
            "weighted avg      0.918     0.912     0.915      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "not a good model"
      ],
      "metadata": {
        "id": "h1wd4_b9j3Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Define Base Learners\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, class_weight='balanced', random_state=42)),\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=42)),\n",
        "]\n",
        "\n",
        "# 3. Define Meta-Learner\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# 4. Create Stacking Classifier\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_learner,\n",
        "    cv=5,  # internal cross-validation for base learners\n",
        "    passthrough=False,  # set to True to pass original features + predictions to meta-learner\n",
        "    stack_method='predict_proba'  # use class probabilities for stacking\n",
        ")\n",
        "\n",
        "# 5. Train\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict\n",
        "y_pred = stack_model.predict(X_test)\n",
        "\n",
        "# 7. Evaluate\n",
        "print(classification_report(y_test, y_pred, digits=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPa30pQdwxl5",
        "outputId": "e2380d26-7278-4576-d2d0-b94f05038505"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.943     0.950     0.946       855\n",
            "           1      0.691     0.662     0.676       145\n",
            "\n",
            "    accuracy                          0.908      1000\n",
            "   macro avg      0.817     0.806     0.811      1000\n",
            "weighted avg      0.906     0.908     0.907      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "not a good model for 1"
      ],
      "metadata": {
        "id": "B0DNVaY7kDTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Define 5 diverse base learners\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, class_weight='balanced', random_state=42)),\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=42)),\n",
        "    ('knn', make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5))),  # scale needed\n",
        "    ('gnb', GaussianNB()),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42))\n",
        "]\n",
        "\n",
        "# 3. Meta-model: SVM with scaling and probability output\n",
        "meta_model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(kernel='rbf', probability=True, random_state=42)\n",
        ")\n",
        "\n",
        "# 4. Create the stacking classifier\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_model,\n",
        "    stack_method='predict_proba',\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# 5. Train the stack\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = stack_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, digits=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXK4-nP91V5U",
        "outputId": "26cc39e3-1251-497b-fc65-d544e70c5c1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.955     0.977     0.966       855\n",
            "           1      0.841     0.731     0.782       145\n",
            "\n",
            "    accuracy                          0.941      1000\n",
            "   macro avg      0.898     0.854     0.874      1000\n",
            "weighted avg      0.939     0.941     0.939      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "performance improved"
      ],
      "metadata": {
        "id": "xRxtOWHjkT-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Define 10 diverse base learners\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, class_weight='balanced', random_state=42)),\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=42)),\n",
        "    ('knn', make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5))),\n",
        "    ('gnb', GaussianNB()),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)),\n",
        "    ('et', ExtraTreesClassifier(n_estimators=100, random_state=42)),\n",
        "    ('ada', AdaBoostClassifier(n_estimators=100, random_state=42)),\n",
        "    ('logreg', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)),\n",
        "    ('sgd', make_pipeline(StandardScaler(), SGDClassifier(loss='log_loss', max_iter=1000, class_weight='balanced', random_state=42))),\n",
        "    ('svc', make_pipeline(StandardScaler(), SVC(kernel='rbf', probability=True, random_state=42)))\n",
        "]\n",
        "\n",
        "# 3. Define SVM as meta-model\n",
        "meta_model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(kernel='rbf', probability=True, random_state=42)\n",
        ")\n",
        "\n",
        "# 4. Create stacking classifier\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_model,\n",
        "    stack_method='predict_proba',\n",
        "    cv=5,\n",
        "    n_jobs=-1  # speed up training\n",
        ")\n",
        "\n",
        "# 5. Train\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = stack_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, digits=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoffKDCv2KlI",
        "outputId": "5f3a9421-6553-4f90-ba9d-792b26a9253b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.959     0.982     0.971      1425\n",
            "           1      0.879     0.752     0.811       242\n",
            "\n",
            "    accuracy                          0.949      1667\n",
            "   macro avg      0.919     0.867     0.891      1667\n",
            "weighted avg      0.947     0.949     0.947      1667\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KyXFhKet3wug"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and preprocess dataset\n",
        "df = pd.read_csv(\"churn.csv\")\n",
        "df.rename(columns={'Churn?': 'Churn'}, inplace=True)\n",
        "df['Churn'] = LabelEncoder().fit_transform(df['Churn'])\n",
        "df.drop(columns=['State', 'Phone'], inplace=True)\n",
        "for col in [\"Int'l Plan\", 'VMail Plan']:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "X = df.drop(columns=['Churn'])\n",
        "y = df['Churn']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 10 Base models\n",
        "base_models = [\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=1)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=2)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=3)),\n",
        "    ('ada', AdaBoostClassifier(n_estimators=50, random_state=4)),\n",
        "    ('et', ExtraTreesClassifier(n_estimators=50, random_state=5)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=6)),\n",
        "    ('sgd', SGDClassifier(max_iter=1000, tol=1e-3, random_state=7)),\n",
        "    ('nb', GaussianNB()),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "    ('svc', SVC(probability=True, random_state=8)),\n",
        "]\n",
        "\n",
        "# Define 3 meta-models\n",
        "meta_models = {\n",
        "    'rf_meta': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'lr_meta': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'gb_meta': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "}\n",
        "\n",
        "# Train 3 stacking classifiers with the same base but different meta-models\n",
        "stacking_models = {}\n",
        "for name, meta_model in meta_models.items():\n",
        "    stacking = StackingClassifier(\n",
        "        estimators=base_models,\n",
        "        final_estimator=meta_model,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "    stacking.fit(X_train, y_train)\n",
        "    stacking_models[name] = stacking\n",
        "\n",
        "# Get predictions from each stacking model\n",
        "preds = []\n",
        "for name, model in stacking_models.items():\n",
        "    preds.append(model.predict(X_test))\n",
        "\n",
        "# Convert list of arrays to numpy array (shape: 3 x number_of_samples)\n",
        "preds = np.array(preds)\n",
        "\n",
        "# Majority vote across meta-model predictions (axis=0 over models)\n",
        "from scipy.stats import mode\n",
        "final_preds, _ = mode(preds, axis=0)\n",
        "\n",
        "# final_preds is 2D (1 x n), flatten it\n",
        "final_preds = final_preds.flatten()\n",
        "\n",
        "# Evaluate majority vote predictions\n",
        "print(\"Classification Report for Majority Vote Ensemble Meta-model:\")\n",
        "print(classification_report(y_test, final_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni4qgaso_sA7",
        "outputId": "33f9b1b5-10b7-42d9-ec7e-c4799eff767b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Majority Vote Ensemble Meta-model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       855\n",
            "           1       0.88      0.77      0.82       145\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.92      0.87      0.90      1000\n",
            "weighted avg       0.95      0.95      0.95      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta_models = {\n",
        "    'naive_bayes': GaussianNB(),\n",
        "    'knn': KNeighborsClassifier(),\n",
        "    'svm': SVC(probability=True, random_state=42),\n",
        "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "for name, meta in meta_models.items():\n",
        "    stacking = StackingClassifier(\n",
        "        estimators=base_models,\n",
        "        final_estimator=meta,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "    stacking.fit(X_train, y_train)\n",
        "    preds = stacking.predict(X_test)\n",
        "    print(f\"\\nMeta-model: {name}\")\n",
        "    print(classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvIQIs8QB80O",
        "outputId": "0acc01af-b88f-42a9-e4ca-fc64c3247d28"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Meta-model: naive_bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95       855\n",
            "           1       0.67      0.84      0.74       145\n",
            "\n",
            "    accuracy                           0.92      1000\n",
            "   macro avg       0.82      0.89      0.85      1000\n",
            "weighted avg       0.93      0.92      0.92      1000\n",
            "\n",
            "\n",
            "Meta-model: knn\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       855\n",
            "           1       0.88      0.74      0.80       145\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.92      0.86      0.89      1000\n",
            "weighted avg       0.95      0.95      0.95      1000\n",
            "\n",
            "\n",
            "Meta-model: svm\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       855\n",
            "           1       0.90      0.71      0.80       145\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.93      0.85      0.88      1000\n",
            "weighted avg       0.95      0.95      0.94      1000\n",
            "\n",
            "\n",
            "Meta-model: logistic_regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       855\n",
            "           1       0.89      0.76      0.82       145\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.92      0.87      0.89      1000\n",
            "weighted avg       0.95      0.95      0.95      1000\n",
            "\n",
            "\n",
            "Meta-model: random_forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       855\n",
            "           1       0.89      0.75      0.81       145\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.92      0.87      0.89      1000\n",
            "weighted avg       0.95      0.95      0.95      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#New"
      ],
      "metadata": {
        "id": "FgSAvz68B41A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv(\"churn.csv\")\n",
        "df.rename(columns={'Churn?': 'Churn'}, inplace=True)\n",
        "X = df.drop(columns=['Churn', 'State', 'Phone'])\n",
        "y = LabelEncoder().fit_transform(df['Churn'])\n",
        "\n",
        "categorical_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
        "numeric_cols = [c for c in X.columns if X[c].dtype != 'object']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "])\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=21\n",
        ")\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train_raw)\n",
        "X_test = preprocessor.transform(X_test_raw)\n",
        "\n",
        "base_models = [\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=1)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=2)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=3)),\n",
        "    #('ada', AdaBoostClassifier(n_estimators=50, random_state=4)),\n",
        "    ('et', ExtraTreesClassifier(n_estimators=50, random_state=5)),\n",
        "    #('lr', LogisticRegression(max_iter=1000, random_state=6)),\n",
        "    #('nb', GaussianNB()),\n",
        "    #('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "    ('svc', SVC(probability=True, random_state=7)),\n",
        "   # ('sgd', SGDClassifier(max_iter=1000, tol=1e-3, random_state=8))\n",
        "]\n",
        "\n",
        "# Define 5 meta-models\n",
        "meta_models = {\n",
        "    'naive_bayes': GaussianNB(),\n",
        "    #'knn': KNeighborsClassifier(),\n",
        "    #'svm': SVC(probability=True, random_state=42),\n",
        "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Train stacking models with different meta-models and collect predictions\n",
        "predictions = []\n",
        "\n",
        "for name, meta in meta_models.items():\n",
        "    stacking = StackingClassifier(\n",
        "        estimators=base_models,\n",
        "        final_estimator=meta,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "    stacking.fit(X_train, y_train)\n",
        "    preds = stacking.predict(X_test)\n",
        "    predictions.append(preds)\n",
        "    print(f\"\\nMeta-model: {name}\")\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "# Convert to numpy array (shape: 5 x n_samples)\n",
        "predictions = np.array(predictions)\n",
        "\n",
        "# Majority vote across meta-model predictions for each sample\n",
        "final_preds, _ = mode(predictions, axis=0)\n",
        "final_preds = final_preds.flatten()\n",
        "\n",
        "print(\"\\nFinal Majority Vote Ensemble Classification Report:\")\n",
        "print(classification_report(y_test, final_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frxI5KGICCox",
        "outputId": "ee884ded-1b98-4ef2-d600-0c136b519604"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Meta-model: naive_bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96       855\n",
            "           1       0.74      0.86      0.79       145\n",
            "\n",
            "    accuracy                           0.94      1000\n",
            "   macro avg       0.86      0.90      0.88      1000\n",
            "weighted avg       0.94      0.94      0.94      1000\n",
            "\n",
            "\n",
            "Meta-model: logistic_regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       855\n",
            "           1       0.86      0.79      0.82       145\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.91      0.89      0.90      1000\n",
            "weighted avg       0.95      0.95      0.95      1000\n",
            "\n",
            "\n",
            "Meta-model: random_forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       855\n",
            "           1       0.84      0.78      0.81       145\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.90      0.88      0.89      1000\n",
            "weighted avg       0.95      0.95      0.95      1000\n",
            "\n",
            "\n",
            "Final Majority Vote Ensemble Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       855\n",
            "           1       0.84      0.81      0.82       145\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.90      0.89      0.90      1000\n",
            "weighted avg       0.95      0.95      0.95      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meta-model: random_forest\\\n",
        "Meta-model: logistic_regression"
      ],
      "metadata": {
        "id": "hIG7VsI-GdhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv(\"churn.csv\")\n",
        "df.rename(columns={'Churn?': 'Churn'}, inplace=True)\n",
        "X = df.drop(columns=['Churn', 'State', 'Phone'])\n",
        "y = LabelEncoder().fit_transform(df['Churn'])\n",
        "\n",
        "# Split feature types\n",
        "categorical_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
        "numeric_cols = [c for c in X.columns if X[c].dtype != 'object']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "])\n",
        "\n",
        "# Train-test split\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=21\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train = preprocessor.fit_transform(X_train_raw)\n",
        "X_test = preprocessor.transform(X_test_raw)\n",
        "\n",
        "# Define two base models\n",
        "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train both\n",
        "model_lr.fit(X_train, y_train)\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "probs_lr = model_lr.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
        "probs_rf = model_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Average the probabilities\n",
        "avg_probs = (probs_lr + probs_rf) / 2\n",
        "\n",
        "# Make final predictions with threshold = 0.5\n",
        "final_preds = (avg_probs >= 0.5).astype(int)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Final Averaged Probability Ensemble Classification Report:\")\n",
        "print(classification_report(y_test, final_preds))\n"
      ],
      "metadata": {
        "id": "7CX0L1kUCen2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809075eb-030e-48c1-a90d-077ec9bf0123"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Averaged Probability Ensemble Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.96       855\n",
            "           1       0.91      0.52      0.66       145\n",
            "\n",
            "    accuracy                           0.92      1000\n",
            "   macro avg       0.92      0.75      0.81      1000\n",
            "weighted avg       0.92      0.92      0.91      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv(\"churn.csv\")\n",
        "df.rename(columns={'Churn?': 'Churn'}, inplace=True)\n",
        "X = df.drop(columns=['Churn', 'State', 'Phone'])\n",
        "y = LabelEncoder().fit_transform(df['Churn'])\n",
        "\n",
        "# Identify feature types\n",
        "categorical_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
        "numeric_cols = [c for c in X.columns if X[c].dtype != 'object']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "])\n",
        "\n",
        "# Split data\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=21\n",
        ")\n",
        "X_train = preprocessor.fit_transform(X_train_raw)\n",
        "X_test = preprocessor.transform(X_test_raw)\n",
        "\n",
        "# Base models\n",
        "base_models = [\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=1)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=2)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=3)),\n",
        "    ('ada', AdaBoostClassifier(n_estimators=50, random_state=4)),\n",
        "    ('et', ExtraTreesClassifier(n_estimators=50, random_state=5)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=6)),\n",
        "    ('nb', GaussianNB()),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "    ('svc', SVC(probability=True, random_state=7)),\n",
        "    ('sgd', SGDClassifier(max_iter=1000, tol=1e-3, random_state=8)),\n",
        "]\n",
        "\n",
        "# Meta models\n",
        "meta_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "meta_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train stacking models\n",
        "stack_lr = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_lr,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "stack_rf = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_rf,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "\n",
        "stack_lr.fit(X_train, y_train)\n",
        "stack_rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities from both meta models\n",
        "probs_lr = stack_lr.predict_proba(X_test)[:, 1]\n",
        "probs_rf = stack_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Average probabilities\n",
        "avg_probs = (probs_lr + probs_rf) / 2\n",
        "\n",
        "# Final prediction using threshold\n",
        "final_preds = (avg_probs >= 0.5).astype(int)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Final Meta-Ensemble Classification Report:\")\n",
        "print(classification_report(y_test, final_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMNuorLFcFA4",
        "outputId": "024761ad-db5f-40c7-b7de-01669fcf0405"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Meta-Ensemble Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       855\n",
            "           1       0.87      0.80      0.83       145\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.92      0.89      0.90      1000\n",
            "weighted avg       0.95      0.95      0.95      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Load data\n",
        "df = pd.read_csv(\"churn.csv\")\n",
        "df.rename(columns={'Churn?': 'Churn'}, inplace=True)\n",
        "X = df.drop(columns=['Churn', 'State', 'Phone'])\n",
        "y = LabelEncoder().fit_transform(df['Churn'])\n",
        "\n",
        "# 2. Preprocessing\n",
        "categorical_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
        "numeric_cols = [c for c in X.columns if X[c].dtype != 'object']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "])\n",
        "\n",
        "X = preprocessor.fit_transform(X)\n",
        "\n",
        "# 3. Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Base models (tuples: name, model)\n",
        "base_models = [\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=1)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=2)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=3)),\n",
        "    #('ada', AdaBoostClassifier(n_estimators=50, random_state=4)),\n",
        "    ('et', ExtraTreesClassifier(n_estimators=50, random_state=5)),\n",
        "    #('lr', LogisticRegression(max_iter=1000, random_state=6)),\n",
        "    #('nb', GaussianNB()),\n",
        "    #('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "    ('svc', SVC(probability=True, random_state=7)),\n",
        "   # ('sgd', SGDClassifier(max_iter=1000, tol=1e-3, random_state=8))\n",
        "]\n",
        "\n",
        "# 5. Generate base model predictions as meta features\n",
        "def get_meta_features(models, X_train, y_train, X_test, n_folds=5):\n",
        "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    train_meta = np.zeros((X_train.shape[0], len(models)))\n",
        "    test_meta = np.zeros((X_test.shape[0], len(models)))\n",
        "\n",
        "    for i, (name, model) in enumerate(models):  # ✅ unpack (name, model)\n",
        "        test_meta_fold = np.zeros((n_folds, X_test.shape[0]))\n",
        "        for j, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
        "            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "            # Train model\n",
        "            model.fit(X_tr, y_tr)\n",
        "\n",
        "            # Handle models without predict_proba (like SGD)\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                val_preds = model.predict_proba(X_val)[:, 1]\n",
        "                test_preds = model.predict_proba(X_test)[:, 1]\n",
        "            else:\n",
        "                val_preds = model.decision_function(X_val)\n",
        "                val_preds = (val_preds - val_preds.min()) / (val_preds.max() - val_preds.min() + 1e-8)  # normalize\n",
        "                test_preds = model.decision_function(X_test)\n",
        "                test_preds = (test_preds - test_preds.min()) / (test_preds.max() - test_preds.min() + 1e-8)\n",
        "\n",
        "            train_meta[val_idx, i] = val_preds\n",
        "            test_meta_fold[j] = test_preds\n",
        "\n",
        "        test_meta[:, i] = test_meta_fold.mean(axis=0)\n",
        "\n",
        "    return train_meta, test_meta\n",
        "\n",
        "# 6. Get meta features\n",
        "train_meta_features, test_meta_features = get_meta_features(\n",
        "    base_models, X_train, y_train, X_test\n",
        ")\n",
        "\n",
        "# 7. Meta models\n",
        "meta_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "meta_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "meta_lr.fit(train_meta_features, y_train)\n",
        "meta_rf.fit(train_meta_features, y_train)\n",
        "\n",
        "# 8. Predict meta-model probabilities\n",
        "probs_lr = meta_lr.predict_proba(test_meta_features)[:, 1]\n",
        "probs_rf = meta_rf.predict_proba(test_meta_features)[:, 1]\n",
        "\n",
        "# 9. Average the probabilities\n",
        "avg_probs = (probs_lr + probs_rf) / 2\n",
        "final_preds = (avg_probs >= 0.5).astype(int)\n",
        "\n",
        "# 10. Final Evaluation\n",
        "print(\"Final Stacked Ensemble Classification Report:\")\n",
        "print(classification_report(y_test, final_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqAs5YUrcqZm",
        "outputId": "3be7415f-ee87-44c3-b755-210fa41f9235"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Stacked Ensemble Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.88      0.79      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.arange(0.3, 0.6, 0.01)\n",
        "for t in thresholds:\n",
        "    preds = (avg_probs >= t).astype(int)\n",
        "    print(f\"\\nThreshold {t:.2f}\")\n",
        "    print(classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlsjMSyKeMOj",
        "outputId": "f4f72d20-5070-49aa-d490-75354c4f787b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Threshold 0.30\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1425\n",
            "           1       0.83      0.82      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.90      0.90      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1425\n",
            "           1       0.83      0.82      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.90      0.90      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.32\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1425\n",
            "           1       0.84      0.82      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.90      0.90      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.33\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1425\n",
            "           1       0.84      0.82      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.90      0.90      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.34\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1425\n",
            "           1       0.84      0.82      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.90      0.90      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.35\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1425\n",
            "           1       0.84      0.82      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.91      0.90      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.36\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1425\n",
            "           1       0.84      0.81      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.90      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.37\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1425\n",
            "           1       0.84      0.81      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.90      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.38\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1425\n",
            "           1       0.84      0.81      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.91      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.39\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.85      0.81      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.91      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.40\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.86      0.81      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.91      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.41\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.87      0.81      0.84       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.89      0.91      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.42\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.88      0.81      0.84       242\n",
            "\n",
            "    accuracy                           0.96      1667\n",
            "   macro avg       0.92      0.90      0.91      1667\n",
            "weighted avg       0.95      0.96      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.43\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.87      0.81      0.84       242\n",
            "\n",
            "    accuracy                           0.96      1667\n",
            "   macro avg       0.92      0.89      0.91      1667\n",
            "weighted avg       0.95      0.96      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.44\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.88      0.80      0.84       242\n",
            "\n",
            "    accuracy                           0.96      1667\n",
            "   macro avg       0.92      0.89      0.91      1667\n",
            "weighted avg       0.95      0.96      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.45\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.88      0.80      0.84       242\n",
            "\n",
            "    accuracy                           0.96      1667\n",
            "   macro avg       0.92      0.89      0.91      1667\n",
            "weighted avg       0.95      0.96      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.46\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.88      0.80      0.84       242\n",
            "\n",
            "    accuracy                           0.96      1667\n",
            "   macro avg       0.92      0.89      0.91      1667\n",
            "weighted avg       0.95      0.96      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.47\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.88      0.80      0.84       242\n",
            "\n",
            "    accuracy                           0.96      1667\n",
            "   macro avg       0.92      0.89      0.91      1667\n",
            "weighted avg       0.95      0.96      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.48\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.88      0.80      0.84       242\n",
            "\n",
            "    accuracy                           0.96      1667\n",
            "   macro avg       0.92      0.89      0.91      1667\n",
            "weighted avg       0.95      0.96      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.49\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1425\n",
            "           1       0.88      0.80      0.84       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.50\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.88      0.79      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.51\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.88      0.79      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.52\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.88      0.79      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.53\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.88      0.79      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.89      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.54\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.88      0.79      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.88      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.55\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.89      0.79      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.93      0.88      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.56\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.89      0.79      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.93      0.88      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.57\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.89      0.79      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.93      0.88      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.58\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.89      0.78      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.88      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n",
            "\n",
            "Threshold 0.59\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1425\n",
            "           1       0.89      0.77      0.83       242\n",
            "\n",
            "    accuracy                           0.95      1667\n",
            "   macro avg       0.92      0.88      0.90      1667\n",
            "weighted avg       0.95      0.95      0.95      1667\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsTxssvmfosq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define your models (unchanged)\n",
        "base_models = [\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=1)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=2)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=3)),\n",
        "    ('ada', AdaBoostClassifier(n_estimators=50, random_state=4)),\n",
        "    ('et', ExtraTreesClassifier(n_estimators=50, random_state=5)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=6)),\n",
        "    ('nb', GaussianNB()),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "    ('svc', SVC(probability=True, random_state=7)),\n",
        "    ('sgd', SGDClassifier(max_iter=1000, tol=1e-3, random_state=8))\n",
        "]\n",
        "\n",
        "# Use StratifiedKFold to preserve class distribution\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Custom scorer (F1-score for class 1)\n",
        "f1 = make_scorer(f1_score, pos_label=1)\n",
        "\n",
        "# Evaluate each model\n",
        "model_scores = []\n",
        "\n",
        "for name, model in base_models:\n",
        "    scores = cross_val_score(model, X, y, scoring=f1, cv=kf, n_jobs=-1)\n",
        "    model_scores.append((name, scores.mean()))\n",
        "    print(f\"{name}: F1-score = {scores.mean():.4f} ± {scores.std():.4f}\")\n",
        "\n",
        "# Sort models by mean F1-score\n",
        "model_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\n🔝 Best models by F1-score:\")\n",
        "for name, score in model_scores:\n",
        "    print(f\"{name}: {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RAgQrGkhnB_",
        "outputId": "cd55ad37-5d07-47ff-801b-4892f90183f2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dt: F1-score = 0.7660 ± 0.0302\n",
            "rf: F1-score = 0.8074 ± 0.0277\n",
            "gb: F1-score = 0.8075 ± 0.0162\n",
            "ada: F1-score = 0.4325 ± 0.0457\n",
            "et: F1-score = 0.7077 ± 0.0232\n",
            "lr: F1-score = 0.3002 ± 0.0507\n",
            "nb: F1-score = 0.4785 ± 0.0334\n",
            "knn: F1-score = 0.3928 ± 0.0216\n",
            "svc: F1-score = 0.6061 ± 0.0163\n",
            "sgd: F1-score = 0.2460 ± 0.0896\n",
            "\n",
            "🔝 Best models by F1-score:\n",
            "gb: 0.8075\n",
            "rf: 0.8074\n",
            "dt: 0.7660\n",
            "et: 0.7077\n",
            "svc: 0.6061\n",
            "nb: 0.4785\n",
            "ada: 0.4325\n",
            "knn: 0.3928\n",
            "lr: 0.3002\n",
            "sgd: 0.2460\n"
          ]
        }
      ]
    }
  ]
}